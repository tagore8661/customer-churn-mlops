# Customer Churn MLOps - KServe InferenceService Configuration
# This file defines the model serving configuration for KServe

apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: churn-predictor
  namespace: churn
  labels:
    app: churn-prediction
    component: model-serving
spec:
  predictor:
    # Use the service account with S3 access
    serviceAccountName: sa-s3-access
    # Configure scikit-learn model server
    sklearn:
      # Model storage URI - points to the model file in S3 bucket
      # This path is automatically updated by the CI/CD pipeline
      storageUri: s3://customer-churn-mlops-tagore/models/churn_model.pkl